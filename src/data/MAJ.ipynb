{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd, sqlite3, requests\r\n",
    "import hockey_scraper as hs\r\n",
    "import numpy as np\r\n",
    "from datetime import date, timedelta, datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP WHERE Date < '2017-07-01'\", conn)\r\n",
    "maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "maxDate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2017-02-28'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#variables globales\r\n",
    "\r\n",
    "conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "fin = \" WHERE EVENT = 'GOAL' AND Period <> '5' AND PBP.Date >= ALIGNEMENTS.dateDebut AND PBP.Date <= ALIGNEMENTS.dateFin AND PBP.Date >= '2021-01-13' GROUP BY idAlignement)) WHERE idAlignement = ALIGNEMENTS.idAlignement)\"\r\n",
    "\r\n",
    "#scrape les points\r\n",
    "def scrapePoints():\r\n",
    "    ok = \"Scrape fait\"\r\n",
    "    pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP\", conn)\r\n",
    "    maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "    maxDate = pd.to_datetime(maxDate) + timedelta(days=1)\r\n",
    "    maxDate = maxDate.strftime(\"%Y-%m-%d\")\r\n",
    "    ajd = date.today()\r\n",
    "    ajd = ajd.strftime(\"%Y-%m-%d\")\r\n",
    "\r\n",
    "    try:\r\n",
    "        scrape = hs.nhl.scrape_functions.scrape_date_range(maxDate, ajd,\r\n",
    "                                if_scrape_shifts=True, data_format='pandas', preseason=False, rescrape=False, docs_dir=True)\r\n",
    "        \r\n",
    "        #pbp\r\n",
    "        dfPBP = scrape[\"pbp\"]\r\n",
    "        dfPBP.to_sql('PBP', conn, if_exists='append', index = False)\r\n",
    "\r\n",
    "        #shifts\r\n",
    "        dfshifts = scrape[\"shifts\"]\r\n",
    "        dfshifts.to_sql('SHIFTS', conn, if_exists='append', index = False)\r\n",
    "    except:\r\n",
    "        print(\"PBP à jour\")\r\n",
    "    return ok\r\n",
    "\r\n",
    "#fonctions\r\n",
    "def execSQL(sql, conn, write=False):\r\n",
    "    c = conn.cursor()\r\n",
    "    print(c.execute(sql))\r\n",
    "    if write:\r\n",
    "        conn.commit()\r\n",
    "    else:\r\n",
    "        print(c.fetchall())\r\n",
    "    c.close()\r\n",
    "\r\n",
    "def writeUpdateDebut(typeScore):\r\n",
    "    updateDebut = \"UPDATE ALIGNEMENTS SET \" + typeScore + \"Actuels = (SELECT Nb\" + typeScore + \" FROM ((SELECT idAlignement, COUNT(Event) AS Nb\" + typeScore + \" FROM PBP INNER JOIN ALIGNEMENTS ON\"\r\n",
    "    return updateDebut\r\n",
    "    \r\n",
    "def majInterne(typeScore):\r\n",
    "    debut = writeUpdateDebut(typeScore)\r\n",
    "    if typeScore == \"buts\":\r\n",
    "        milieu = \" (PBP.p1_ID = ALIGNEMENTS.idNHL)\"\r\n",
    "    elif typeScore == \"assist\":\r\n",
    "        milieu = \" (PBP.p2_ID = ALIGNEMENTS.idNHL) OR (PBP.p3_ID = ALIGNEMENTS.idNHL)\"\r\n",
    "    sqlUpdate = debut + milieu + fin\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "\r\n",
    "def writeSetZero(typeScore):\r\n",
    "    setZero = \"UPDATE ALIGNEMENTS SET \" + typeScore + \"Actuels = 0 WHERE \" + typeScore + \"Actuels IS NULL\"\r\n",
    "    return setZero\r\n",
    "\r\n",
    "def majPointsAlignements():\r\n",
    "    setButsZero = writeSetZero(\"buts\")\r\n",
    "    setAssistZero = writeSetZero(\"assist\")\r\n",
    "    setPtsZero = writeSetZero(\"points\")\r\n",
    "    sqlUpdate = \"UPDATE ALIGNEMENTS SET pointsActuels = (butsActuels + assistActuels)\"\r\n",
    "    execSQL(setButsZero, conn, write = True)\r\n",
    "    execSQL(setAssistZero, conn, write = True)\r\n",
    "    execSQL(setPtsZero, conn, write = True)\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "\r\n",
    "def majPJ():\r\n",
    "    sqlUpdate = \"UPDATE ALIGNEMENTS SET pjActuels = (SELECT NbPJ FROM (SELECT idAlignement, COUNT(DISTINCT Game_Id) AS NbPJ FROM SHIFTS INNER JOIN ALIGNEMENTS ON (SHIFTS.Player_Id = ALIGNEMENTS.idNHL) AND SHIFTS.Date >= ALIGNEMENTS.dateDebut AND SHIFTS.Date <= ALIGNEMENTS.dateFin AND SHIFTS.Date >= '2021-01-13' GROUP BY idAlignement) WHERE idAlignement = ALIGNEMENTS.idAlignement)\"\r\n",
    "    updateNull = \"UPDATE ALIGNEMENTS SET pjActuels = 0 WHERE pjActuels IS NULL\"\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "    execSQL(updateNull, conn, write = True)\r\n",
    "\r\n",
    "def majPJBPPAlign():\r\n",
    "    majInterne(\"buts\")\r\n",
    "    majInterne(\"assist\")\r\n",
    "    majPointsAlignements()\r\n",
    "    majPJ()\r\n",
    "\r\n",
    "def majScorePoolers():\r\n",
    "    sqlUpdate = \"UPDATE POOLERS SET PJ = (SELECT NbPJ FROM (SELECT idPooler, SUM(pjActuels) AS NbPJ FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler), B = (SELECT NbB FROM (SELECT idPooler, SUM(butsActuels) AS NbB FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler), A = (SELECT NbA FROM (SELECT idPooler, SUM(assistActuels) AS NbA FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler), Score = (SELECT NbSc FROM (SELECT idPooler, SUM(pointsActuels) AS NbSc FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler)\"\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "    \r\n",
    "#maj du score des gardiens\r\n",
    "def logGardien(idNHL):\r\n",
    "    jsonJoueur = requests.get(\"https://statsapi.web.nhl.com/api/v1/people/\" + idNHL + \"/stats?stats=gameLog&season=20202021\").json()\r\n",
    "    df = pd.json_normalize(jsonJoueur[\"stats\"][0][\"splits\"])\r\n",
    "    gardienLogs = df[[\"season\", \"date\", \"isWin\", \"stat.shutouts\"]]\r\n",
    "    gardienLogs[\"gardien\"] = idNHL\r\n",
    "    return gardienLogs\r\n",
    "\r\n",
    "def GwriteUpdate(typeScore):\r\n",
    "    colAl = \"\"\r\n",
    "    if typeScore == \"isWin\":\r\n",
    "        colAl = \"buts\"\r\n",
    "    elif typeScore == \"'stat.shutouts'\":\r\n",
    "        colAl = \"assist\"\r\n",
    "    elif typeScore == \"scorePool\":\r\n",
    "        colAl = \"points\"\r\n",
    "    debut = \"UPDATE ALIGNEMENTS SET \" + colAl + \"Actuels = (SELECT Nb FROM (SELECT gardien, SUM(\" + typeScore + \") AS Nb FROM GARDIENS WHERE dateMatch >= ALIGNEMENTS.dateDebut AND dateMatch <= ALIGNEMENTS.dateFin AND gardien = ALIGNEMENTS.idNHL)) WHERE ALIGNEMENTS.idNHL IN (SELECT DISTINCT(gardien) FROM GARDIENS)\"\r\n",
    "    return debut\r\n",
    "\r\n",
    "def majScoreGardiens():\r\n",
    "    dfGardiens = pd.read_sql(\"SELECT idNHL FROM JOUEURS WHERE position == 'G'\", conn)\r\n",
    "    gardiens = dfGardiens[\"idNHL\"].apply(str)\r\n",
    "    listGardiens = gardiens.values.tolist()\r\n",
    "\r\n",
    "    vraisCol = [\"season\", \"date\", \"isWin\", \"stat.shutouts\", \"gardien\"]\r\n",
    "    gameLogsG = pd.DataFrame(columns=vraisCol)\r\n",
    "    gameLogsG = gameLogsG.fillna(0)\r\n",
    "\r\n",
    "    for i in listGardiens:\r\n",
    "        try:\r\n",
    "            gardienLogs = logGardien(i)\r\n",
    "        except:\r\n",
    "            print(\"fausse alarme (espoir) \" + i)\r\n",
    "        gameLogsG = gameLogsG.append(gardienLogs)\r\n",
    "    gameLogsG = gameLogsG.rename(columns = {\"date\" : \"dateMatch\"})\r\n",
    "    gameLogsG[[\"dateMatch\"]] = gameLogsG.dateMatch.str.split(\" 00:\",expand=True)\r\n",
    "    #gameLogsG[\"dateMatch\"] = pd.to_datetime(gameLogsG[\"dateMatch\"])\r\n",
    "    pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP\", conn)\r\n",
    "    maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "    gameLogsG = gameLogsG[(gameLogsG[\"dateMatch\"] <= maxDate)]\r\n",
    "    \r\n",
    "    a = gameLogsG[\"isWin\"]\r\n",
    "    gameLogsG[\"esWin\"] = a * 2\r\n",
    "    gameLogsG [\"scorePool\"] = gameLogsG[\"esWin\"] + gameLogsG[\"stat.shutouts\"]\r\n",
    "    gameLogsG.to_sql(\"GARDIENS\", conn, if_exists=\"replace\", index=False)\r\n",
    "\r\n",
    "    updVic = GwriteUpdate(\"isWin\")\r\n",
    "    updJB = GwriteUpdate(\"'stat.shutouts'\")\r\n",
    "    updSco = GwriteUpdate(\"scorePool\")\r\n",
    "    execSQL(updVic, conn, write = True)\r\n",
    "    execSQL(updJB, conn, write = True)\r\n",
    "    execSQL(updSco, conn, write = True)\r\n",
    "\r\n",
    "#majMasseSalariale()\r\n",
    "def majMasseSalariale():\r\n",
    "    sqlUpdate = \"UPDATE POOLERS SET MasseSalariale = (SELECT masseActuelle FROM (SELECT idPooler, SUM(salaireActuel) AS masseActuelle FROM ALIGNEMENTS INNER JOIN JOUEURS ON ALIGNEMENTS.idNHL = JOUEURS.idNHL WHERE date('now') BETWEEN ALIGNEMENTS.dateDebut AND ALIGNEMENTS.dateFin AND (statutJoueur = 'Alignement' OR statutJoueur = 'Réserve') GROUP BY idPooler) WHERE Poolers.Id = idPooler)\"\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "\r\n",
    "#maj des json\r\n",
    "def majTables():\r\n",
    "    conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "    var = 'OK'\r\n",
    "    try:\r\n",
    "        #maj Poolers\r\n",
    "        dfPoolers = pd.read_sql(\"SELECT * FROM POOLERS\", conn)\r\n",
    "        jsonPoolers = dfPoolers.to_json(\"C:/dev/pool-de-hockey/src/data/poolers.json\", orient = \"table\", index =    False, indent = 4)\r\n",
    "    except Exception as ex:\r\n",
    "        print(\"Erreur : poolers\")\r\n",
    "        var = \"Erreur poolers\"\r\n",
    "\r\n",
    "    try:\r\n",
    "        #maj Alignements\r\n",
    "        requete = \"SELECT * FROM ALIGNEMENTS INNER JOIN JOUEURS ON JOUEURS.idNHL = ALIGNEMENTS.idNHL\"\r\n",
    "        dfTempo = pd.read_sql(requete, conn)\r\n",
    "        dfAlignements = dfTempo.T.drop_duplicates().T\r\n",
    "        jsonAlignements = dfAlignements.to_json(\"C:/dev/pool-de-hockey/src/data/alignements.json\", orient = \"table\", index = False, indent = 4)\r\n",
    "    except Exception as ex2:\r\n",
    "        print(\"Erreur : alignements\")\r\n",
    "        var = \"Erreur alignements\"\r\n",
    "\r\n",
    "    try:\r\n",
    "        #maj Joueurs\r\n",
    "        dfJoueurs = pd.read_sql(\"SELECT * FROM JOUEURS\", conn)\r\n",
    "        jsonJoueurs = dfJoueurs.to_json(\"C:/dev/pool-de-hockey/src/data/joueurs.json\", orient = \"table\", index = False, indent = 4)\r\n",
    "    except Exception as ex3:\r\n",
    "        print(\"Erreur : joueurs\")\r\n",
    "        var = \"Erreur joueurs\"\r\n",
    "\r\n",
    "    return var\r\n",
    "\r\n",
    "\r\n",
    "def scrape_dates(date_inf, date_sup):\r\n",
    "    ok = \"Scrape fait\"\r\n",
    "    test = pd.date_range(date_inf,date_sup)\r\n",
    "    pbpDates = pd.read_sql(\"SELECT DISTINCT(Date) FROM PBP\", conn)\r\n",
    "    dates = pbpDates[\"Date\"]\r\n",
    "    result = []\r\n",
    "    for i in dates:\r\n",
    "        if i in test:\r\n",
    "            result.append(1)\r\n",
    "        else:\r\n",
    "            result.append(0)\r\n",
    "    if sum(result) > 0:\r\n",
    "        return \"Erreur: tentative de scraper des dates qui sont déjà dans SQLite.\"\r\n",
    "    else:\r\n",
    "        try:\r\n",
    "            scrape = hs.nhl.scrape_functions.scrape_date_range(date_inf, date_sup,\r\n",
    "                                    if_scrape_shifts=True, data_format='pandas', preseason=False, rescrape=False, docs_dir=True)\r\n",
    "\r\n",
    "            #pbp\r\n",
    "            dfPBP = scrape[\"pbp\"]\r\n",
    "            dfPBP.to_sql('PBP', conn, if_exists='append', index = False)\r\n",
    "\r\n",
    "            #shifts\r\n",
    "            dfshifts = scrape[\"shifts\"]\r\n",
    "            dfshifts.to_sql('SHIFTS', conn, if_exists='append', index = False)\r\n",
    "        except:\r\n",
    "            print(\"PBP à jour\")\r\n",
    "        return ok\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#scrapePoints()\r\n",
    "print(\"1\")\r\n",
    "#majPJBPPAlign()\r\n",
    "print(\"2\")\r\n",
    "#majScoreGardiens()\r\n",
    "print(\"3\")\r\n",
    "#majScorePoolers()\r\n",
    "print(\"4\")\r\n",
    "majMasseSalariale()\r\n",
    "print(\"5\")\r\n",
    "majTables()\r\n",
    "print(\"6\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "<sqlite3.Cursor object at 0x000001C20159B1F0>\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#avant de commencer le scraping, il faut voir si j'ai des matchs en trop\r\n",
    "conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "df_test = pd.read_sql(\"SELECT Game_Id, Date, Event, Away_Team, Home_Team FROM PBP WHERE Event IS 'GEND'\", conn)\r\n",
    "team = \"OTT\"\r\n",
    "df_test[\"is_AMTL\"] = np.where(df_test[\"Away_Team\"] == team,\r\n",
    "                    1, 0)\r\n",
    "df_test[\"is_HMTL\"] = np.where(df_test[\"Home_Team\"] == team,\r\n",
    "                    1, 0)\r\n",
    "df_test[\"is_MTL\"] = df_test[\"is_AMTL\"] + df_test[\"is_HMTL\"]                    \r\n",
    "df_test = df_test[df_test[\"is_MTL\"] == 1]\r\n",
    "df_test[['Annee','Mois','Jour']] = df_test['Date'].str.split('-',expand=True)\r\n",
    "df_test[\"Annee\"] = pd.to_numeric(df_test[\"Annee\"])\r\n",
    "df_test[\"Mois\"] = pd.to_numeric(df_test[\"Mois\"])\r\n",
    "df_test[\"saison_series\"] =  df_test['Game_Id'].astype(str).str[0]\r\n",
    "df_test = df_test[df_test[\"saison_series\"] == \"2\"]\r\n",
    "df_test[\"Saison\"] = np.where(df_test[\"Mois\"] > 8,\r\n",
    "                    df_test[\"Annee\"], df_test[\"Annee\"] - 1)\r\n",
    "df_test[\"Saison\"] = df_test[\"Saison\"].map(str)\r\n",
    "df_test[\"Game_Id\"] = df_test[\"Saison\"] + df_test[\"Game_Id\"]\r\n",
    "df_agg = df_test.groupby(['Saison']).count()\r\n",
    "df2020 = df_test[df_test[\"Saison\"] == \"2020\"]\r\n",
    "## Tout semble correct!\r\n",
    "df_agg\r\n",
    "#note: df_agg permet de voir le nb de matchs par saison d'une équipe dans la db."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Event</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>is_AMTL</th>\n",
       "      <th>is_HMTL</th>\n",
       "      <th>is_MTL</th>\n",
       "      <th>Annee</th>\n",
       "      <th>Mois</th>\n",
       "      <th>Jour</th>\n",
       "      <th>saison_series</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saison</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Game_Id  Date  Event  Away_Team  Home_Team  is_AMTL  is_HMTL  is_MTL  \\\n",
       "Saison                                                                         \n",
       "2017         81    81     81         81         81       81       81      81   \n",
       "2018         82    82     82         82         82       82       82      82   \n",
       "2019         71    71     71         71         71       71       71      71   \n",
       "2020         55    55     55         55         55       55       55      55   \n",
       "\n",
       "        Annee  Mois  Jour  saison_series  \n",
       "Saison                                    \n",
       "2017       81    81    81             81  \n",
       "2018       82    82    82             82  \n",
       "2019       71    71    71             71  \n",
       "2020       55    55    55             55  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP\", conn)\r\n",
    "maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "#maxDate = maxDate.strftime(\"%Y-%m-%d\")\r\n",
    "maxDate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2021-02-28'"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#scraper la saison 2016-2017\r\n",
    "#la saison commence le 12 octobre 2016\r\n",
    "# et finit le 9 avril 2017\r\n",
    "\r\n",
    "#rendu au 1er mars 2017 (exécuter le scraping qui est là live)\r\n",
    "scrape_dates(\"2017-04-01\", \"2017-04-09\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping Game  2016021157 2017-04-01\n",
      "Scraping Game  2016021158 2017-04-01\n",
      "Scraping Game  2016021163 2017-04-01\n",
      "Scraping Game  2016021159 2017-04-01\n",
      "Scraping Game  2016021160 2017-04-01\n",
      "Scraping Game  2016021161 2017-04-01\n",
      "Scraping Game  2016021162 2017-04-01\n",
      "Scraping Game  2016021164 2017-04-01\n",
      "Scraping Game  2016021165 2017-04-02\n",
      "Scraping Game  2016021166 2017-04-02\n",
      "Scraping Game  2016021170 2017-04-02\n",
      "Scraping Game  2016021167 2017-04-02\n",
      "Scraping Game  2016021171 2017-04-02\n",
      "Scraping Game  2016021168 2017-04-02\n",
      "Scraping Game  2016021169 2017-04-02\n",
      "Scraping Game  2016021172 2017-04-02\n",
      "Scraping Game  2016021173 2017-04-02\n",
      "Scraping Game  2016021174 2017-04-02\n",
      "Scraping Game  2016021175 2017-04-02\n",
      "Scraping Game  2016021176 2017-04-03\n",
      "Scraping Game  2016021177 2017-04-03\n",
      "Scraping Game  2016021178 2017-04-03\n",
      "Scraping Game  2016021179 2017-04-04\n",
      "Scraping Game  2016021180 2017-04-04\n",
      "Scraping Game  2016021181 2017-04-04\n",
      "Scraping Game  2016021182 2017-04-04\n",
      "Scraping Game  2016021183 2017-04-04\n",
      "Scraping Game  2016021184 2017-04-04\n",
      "Scraping Game  2016021185 2017-04-04\n",
      "Scraping Game  2016021186 2017-04-04\n",
      "Scraping Game  2016021187 2017-04-04\n",
      "Scraping Game  2016021188 2017-04-04\n",
      "Scraping Game  2016021189 2017-04-04\n",
      "Scraping Game  2016021190 2017-04-04\n",
      "Scraping Game  2016021191 2017-04-04\n",
      "Scraping Game  2016021192 2017-04-05\n",
      "Scraping Game  2016021193 2017-04-05\n",
      "Scraping Game  2016021194 2017-04-06\n",
      "Scraping Game  2016021195 2017-04-06\n",
      "Scraping Game  2016021196 2017-04-06\n",
      "Scraping Game  2016021197 2017-04-06\n",
      "Scraping Game  2016021198 2017-04-06\n",
      "Scraping Game  2016021199 2017-04-06\n",
      "Scraping Game  2016021200 2017-04-06\n",
      "Scraping Game  2016021201 2017-04-06\n",
      "Scraping Game  2016021202 2017-04-06\n",
      "Scraping Game  2016021203 2017-04-06\n",
      "Scraping Game  2016021204 2017-04-06\n",
      "Scraping Game  2016021205 2017-04-06\n",
      "Scraping Game  2016021206 2017-04-07\n",
      "Scraping Game  2016021207 2017-04-08\n",
      "Scraping Game  2016021208 2017-04-08\n",
      "Scraping Game  2016021209 2017-04-08\n",
      "Scraping Game  2016021220 2017-04-08\n",
      "Scraping Game  2016021210 2017-04-08\n",
      "Scraping Game  2016021215 2017-04-08\n",
      "Scraping Game  2016021211 2017-04-08\n",
      "Scraping Game  2016021212 2017-04-08\n",
      "Scraping Game  2016021213 2017-04-08\n",
      "Scraping Game  2016021214 2017-04-08\n",
      "Scraping Game  2016021216 2017-04-08\n",
      "Scraping Game  2016021217 2017-04-08\n",
      "Scraping Game  2016021218 2017-04-08\n",
      "Scraping Game  2016021219 2017-04-08\n",
      "Scraping Game  2016021221 2017-04-09\n",
      "Scraping Game  2016021222 2017-04-09\n",
      "Scraping Game  2016021223 2017-04-09\n",
      "Scraping Game  2016021225 2017-04-09\n",
      "Scraping Game  2016021224 2017-04-09\n",
      "Scraping Game  2016021226 2017-04-09\n",
      "Scraping Game  2016021227 2017-04-09\n",
      "Scraping Game  2016021228 2017-04-09\n",
      "Scraping Game  2016021229 2017-04-09\n",
      "Scraping Game  2016021230 2017-04-09\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Scrape fait'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  }
 ]
}