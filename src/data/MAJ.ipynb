{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd, sqlite3, requests\r\n",
    "import hockey_scraper as hs\r\n",
    "import numpy as np\r\n",
    "from datetime import date, timedelta, datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP WHERE Date < '2017-07-01'\", conn)\r\n",
    "maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "maxDate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2017-02-28'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#variables globales\r\n",
    "\r\n",
    "conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "fin = \" WHERE EVENT = 'GOAL' AND Period <> '5' AND PBP.Date >= ALIGNEMENTS.dateDebut AND PBP.Date <= ALIGNEMENTS.dateFin AND PBP.Date >= '2021-01-13' GROUP BY idAlignement)) WHERE idAlignement = ALIGNEMENTS.idAlignement)\"\r\n",
    "\r\n",
    "#scrape les points\r\n",
    "def scrapePoints():\r\n",
    "    ok = \"Scrape fait\"\r\n",
    "    pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP\", conn)\r\n",
    "    maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "    maxDate = pd.to_datetime(maxDate) + timedelta(days=1)\r\n",
    "    maxDate = maxDate.strftime(\"%Y-%m-%d\")\r\n",
    "    ajd = date.today()\r\n",
    "    ajd = ajd.strftime(\"%Y-%m-%d\")\r\n",
    "\r\n",
    "    try:\r\n",
    "        scrape = hs.nhl.scrape_functions.scrape_date_range(maxDate, ajd,\r\n",
    "                                if_scrape_shifts=True, data_format='pandas', preseason=False, rescrape=False, docs_dir=True)\r\n",
    "        \r\n",
    "        #pbp\r\n",
    "        dfPBP = scrape[\"pbp\"]\r\n",
    "        dfPBP.to_sql('PBP', conn, if_exists='append', index = False)\r\n",
    "\r\n",
    "        #shifts\r\n",
    "        dfshifts = scrape[\"shifts\"]\r\n",
    "        dfshifts.to_sql('SHIFTS', conn, if_exists='append', index = False)\r\n",
    "    except:\r\n",
    "        print(\"PBP à jour\")\r\n",
    "    return ok\r\n",
    "\r\n",
    "#fonctions\r\n",
    "def execSQL(sql, conn, write=False):\r\n",
    "    c = conn.cursor()\r\n",
    "    print(c.execute(sql))\r\n",
    "    if write:\r\n",
    "        conn.commit()\r\n",
    "    else:\r\n",
    "        print(c.fetchall())\r\n",
    "    c.close()\r\n",
    "\r\n",
    "def writeUpdateDebut(typeScore):\r\n",
    "    updateDebut = \"UPDATE ALIGNEMENTS SET \" + typeScore + \"Actuels = (SELECT Nb\" + typeScore + \" FROM ((SELECT idAlignement, COUNT(Event) AS Nb\" + typeScore + \" FROM PBP INNER JOIN ALIGNEMENTS ON\"\r\n",
    "    return updateDebut\r\n",
    "    \r\n",
    "def majInterne(typeScore):\r\n",
    "    debut = writeUpdateDebut(typeScore)\r\n",
    "    if typeScore == \"buts\":\r\n",
    "        milieu = \" (PBP.p1_ID = ALIGNEMENTS.idNHL)\"\r\n",
    "    elif typeScore == \"assist\":\r\n",
    "        milieu = \" (PBP.p2_ID = ALIGNEMENTS.idNHL) OR (PBP.p3_ID = ALIGNEMENTS.idNHL)\"\r\n",
    "    sqlUpdate = debut + milieu + fin\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "\r\n",
    "def writeSetZero(typeScore):\r\n",
    "    setZero = \"UPDATE ALIGNEMENTS SET \" + typeScore + \"Actuels = 0 WHERE \" + typeScore + \"Actuels IS NULL\"\r\n",
    "    return setZero\r\n",
    "\r\n",
    "def majPointsAlignements():\r\n",
    "    setButsZero = writeSetZero(\"buts\")\r\n",
    "    setAssistZero = writeSetZero(\"assist\")\r\n",
    "    setPtsZero = writeSetZero(\"points\")\r\n",
    "    sqlUpdate = \"UPDATE ALIGNEMENTS SET pointsActuels = (butsActuels + assistActuels)\"\r\n",
    "    execSQL(setButsZero, conn, write = True)\r\n",
    "    execSQL(setAssistZero, conn, write = True)\r\n",
    "    execSQL(setPtsZero, conn, write = True)\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "\r\n",
    "def majPJ():\r\n",
    "    sqlUpdate = \"UPDATE ALIGNEMENTS SET pjActuels = (SELECT NbPJ FROM (SELECT idAlignement, COUNT(DISTINCT Game_Id) AS NbPJ FROM SHIFTS INNER JOIN ALIGNEMENTS ON (SHIFTS.Player_Id = ALIGNEMENTS.idNHL) AND SHIFTS.Date >= ALIGNEMENTS.dateDebut AND SHIFTS.Date <= ALIGNEMENTS.dateFin AND SHIFTS.Date >= '2021-01-13' GROUP BY idAlignement) WHERE idAlignement = ALIGNEMENTS.idAlignement)\"\r\n",
    "    updateNull = \"UPDATE ALIGNEMENTS SET pjActuels = 0 WHERE pjActuels IS NULL\"\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "    execSQL(updateNull, conn, write = True)\r\n",
    "\r\n",
    "def majPJBPPAlign():\r\n",
    "    majInterne(\"buts\")\r\n",
    "    majInterne(\"assist\")\r\n",
    "    majPointsAlignements()\r\n",
    "    majPJ()\r\n",
    "\r\n",
    "def majScorePoolers():\r\n",
    "    sqlUpdate = \"UPDATE POOLERS SET PJ = (SELECT NbPJ FROM (SELECT idPooler, SUM(pjActuels) AS NbPJ FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler), B = (SELECT NbB FROM (SELECT idPooler, SUM(butsActuels) AS NbB FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler), A = (SELECT NbA FROM (SELECT idPooler, SUM(assistActuels) AS NbA FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler), Score = (SELECT NbSc FROM (SELECT idPooler, SUM(pointsActuels) AS NbSc FROM ALIGNEMENTS WHERE statutJoueur = 'Alignement' GROUP BY idPooler) WHERE Id = idPooler)\"\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "    \r\n",
    "#maj du score des gardiens\r\n",
    "def logGardien(idNHL):\r\n",
    "    jsonJoueur = requests.get(\"https://statsapi.web.nhl.com/api/v1/people/\" + idNHL + \"/stats?stats=gameLog&season=20202021\").json()\r\n",
    "    df = pd.json_normalize(jsonJoueur[\"stats\"][0][\"splits\"])\r\n",
    "    gardienLogs = df[[\"season\", \"date\", \"isWin\", \"stat.shutouts\"]]\r\n",
    "    gardienLogs[\"gardien\"] = idNHL\r\n",
    "    return gardienLogs\r\n",
    "\r\n",
    "def GwriteUpdate(typeScore):\r\n",
    "    colAl = \"\"\r\n",
    "    if typeScore == \"isWin\":\r\n",
    "        colAl = \"buts\"\r\n",
    "    elif typeScore == \"'stat.shutouts'\":\r\n",
    "        colAl = \"assist\"\r\n",
    "    elif typeScore == \"scorePool\":\r\n",
    "        colAl = \"points\"\r\n",
    "    debut = \"UPDATE ALIGNEMENTS SET \" + colAl + \"Actuels = (SELECT Nb FROM (SELECT gardien, SUM(\" + typeScore + \") AS Nb FROM GARDIENS WHERE dateMatch >= ALIGNEMENTS.dateDebut AND dateMatch <= ALIGNEMENTS.dateFin AND gardien = ALIGNEMENTS.idNHL)) WHERE ALIGNEMENTS.idNHL IN (SELECT DISTINCT(gardien) FROM GARDIENS)\"\r\n",
    "    return debut\r\n",
    "\r\n",
    "def majScoreGardiens():\r\n",
    "    dfGardiens = pd.read_sql(\"SELECT idNHL FROM JOUEURS WHERE position == 'G'\", conn)\r\n",
    "    gardiens = dfGardiens[\"idNHL\"].apply(str)\r\n",
    "    listGardiens = gardiens.values.tolist()\r\n",
    "\r\n",
    "    vraisCol = [\"season\", \"date\", \"isWin\", \"stat.shutouts\", \"gardien\"]\r\n",
    "    gameLogsG = pd.DataFrame(columns=vraisCol)\r\n",
    "    gameLogsG = gameLogsG.fillna(0)\r\n",
    "\r\n",
    "    for i in listGardiens:\r\n",
    "        try:\r\n",
    "            gardienLogs = logGardien(i)\r\n",
    "        except:\r\n",
    "            print(\"fausse alarme (espoir) \" + i)\r\n",
    "        gameLogsG = gameLogsG.append(gardienLogs)\r\n",
    "    gameLogsG = gameLogsG.rename(columns = {\"date\" : \"dateMatch\"})\r\n",
    "    gameLogsG[[\"dateMatch\"]] = gameLogsG.dateMatch.str.split(\" 00:\",expand=True)\r\n",
    "    #gameLogsG[\"dateMatch\"] = pd.to_datetime(gameLogsG[\"dateMatch\"])\r\n",
    "    pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP\", conn)\r\n",
    "    maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "    gameLogsG = gameLogsG[(gameLogsG[\"dateMatch\"] <= maxDate)]\r\n",
    "    \r\n",
    "    a = gameLogsG[\"isWin\"]\r\n",
    "    gameLogsG[\"esWin\"] = a * 2\r\n",
    "    gameLogsG [\"scorePool\"] = gameLogsG[\"esWin\"] + gameLogsG[\"stat.shutouts\"]\r\n",
    "    gameLogsG.to_sql(\"GARDIENS\", conn, if_exists=\"replace\", index=False)\r\n",
    "\r\n",
    "    updVic = GwriteUpdate(\"isWin\")\r\n",
    "    updJB = GwriteUpdate(\"'stat.shutouts'\")\r\n",
    "    updSco = GwriteUpdate(\"scorePool\")\r\n",
    "    execSQL(updVic, conn, write = True)\r\n",
    "    execSQL(updJB, conn, write = True)\r\n",
    "    execSQL(updSco, conn, write = True)\r\n",
    "\r\n",
    "#majMasseSalariale()\r\n",
    "def majMasseSalariale():\r\n",
    "    sqlUpdate = \"UPDATE POOLERS SET MasseSalariale = (SELECT masseActuelle FROM (SELECT idPooler, SUM(salaireActuel) AS masseActuelle FROM ALIGNEMENTS INNER JOIN JOUEURS ON ALIGNEMENTS.idNHL = JOUEURS.idNHL WHERE date('now') BETWEEN ALIGNEMENTS.dateDebut AND ALIGNEMENTS.dateFin AND (statutJoueur = 'Alignement' OR statutJoueur = 'Réserve') GROUP BY idPooler) WHERE Poolers.Id = idPooler)\"\r\n",
    "    execSQL(sqlUpdate, conn, write = True)\r\n",
    "\r\n",
    "#maj des json\r\n",
    "def majTables():\r\n",
    "    conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "    var = 'OK'\r\n",
    "    try:\r\n",
    "        #maj Poolers\r\n",
    "        dfPoolers = pd.read_sql(\"SELECT * FROM POOLERS\", conn)\r\n",
    "        jsonPoolers = dfPoolers.to_json(\"C:/dev/pool-de-hockey/src/data/poolers.json\", orient = \"table\", index =    False, indent = 4)\r\n",
    "    except Exception as ex:\r\n",
    "        print(\"Erreur : poolers\")\r\n",
    "        var = \"Erreur poolers\"\r\n",
    "\r\n",
    "    try:\r\n",
    "        #maj Alignements\r\n",
    "        requete = \"SELECT * FROM ALIGNEMENTS INNER JOIN JOUEURS ON JOUEURS.idNHL = ALIGNEMENTS.idNHL\"\r\n",
    "        dfTempo = pd.read_sql(requete, conn)\r\n",
    "        dfAlignements = dfTempo.T.drop_duplicates().T\r\n",
    "        jsonAlignements = dfAlignements.to_json(\"C:/dev/pool-de-hockey/src/data/alignements.json\", orient = \"table\", index = False, indent = 4)\r\n",
    "    except Exception as ex2:\r\n",
    "        print(\"Erreur : alignements\")\r\n",
    "        var = \"Erreur alignements\"\r\n",
    "\r\n",
    "    try:\r\n",
    "        #maj Joueurs\r\n",
    "        dfJoueurs = pd.read_sql(\"SELECT * FROM JOUEURS\", conn)\r\n",
    "        jsonJoueurs = dfJoueurs.to_json(\"C:/dev/pool-de-hockey/src/data/joueurs.json\", orient = \"table\", index = False, indent = 4)\r\n",
    "    except Exception as ex3:\r\n",
    "        print(\"Erreur : joueurs\")\r\n",
    "        var = \"Erreur joueurs\"\r\n",
    "\r\n",
    "    return var\r\n",
    "\r\n",
    "\r\n",
    "def scrape_dates(date_inf, date_sup):\r\n",
    "    ok = \"Scrape fait\"\r\n",
    "    test = pd.date_range(date_inf,date_sup)\r\n",
    "    pbpDates = pd.read_sql(\"SELECT DISTINCT(Date) FROM PBP\", conn)\r\n",
    "    dates = pbpDates[\"Date\"]\r\n",
    "    result = []\r\n",
    "    for i in dates:\r\n",
    "        if i in test:\r\n",
    "            result.append(1)\r\n",
    "        else:\r\n",
    "            result.append(0)\r\n",
    "    if sum(result) > 0:\r\n",
    "        return \"Erreur: tentative de scraper des dates qui sont déjà dans SQLite.\"\r\n",
    "    else:\r\n",
    "        try:\r\n",
    "            scrape = hs.nhl.scrape_functions.scrape_date_range(date_inf, date_sup,\r\n",
    "                                    if_scrape_shifts=True, data_format='pandas', preseason=False, rescrape=False, docs_dir=True)\r\n",
    "\r\n",
    "            #pbp\r\n",
    "            dfPBP = scrape[\"pbp\"]\r\n",
    "            dfPBP.to_sql('PBP', conn, if_exists='append', index = False)\r\n",
    "\r\n",
    "            #shifts\r\n",
    "            dfshifts = scrape[\"shifts\"]\r\n",
    "            dfshifts.to_sql('SHIFTS', conn, if_exists='append', index = False)\r\n",
    "        except:\r\n",
    "            print(\"PBP à jour\")\r\n",
    "        return ok\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#scrapePoints()\r\n",
    "print(\"1\")\r\n",
    "#majPJBPPAlign()\r\n",
    "print(\"2\")\r\n",
    "#majScoreGardiens()\r\n",
    "print(\"3\")\r\n",
    "#majScorePoolers()\r\n",
    "print(\"4\")\r\n",
    "majMasseSalariale()\r\n",
    "print(\"5\")\r\n",
    "majTables()\r\n",
    "print(\"6\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "<sqlite3.Cursor object at 0x000001C20159B1F0>\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#avant de commencer le scraping, il faut voir si j'ai des matchs en trop\r\n",
    "conn = sqlite3.connect('C:/Users/huber/OneDrive/NHL/DbMatchs.db')\r\n",
    "df_test = pd.read_sql(\"SELECT Game_Id, Date, Event, Away_Team, Home_Team FROM PBP WHERE Event IS 'GEND'\", conn)\r\n",
    "team = \"OTT\"\r\n",
    "df_test[\"is_AMTL\"] = np.where(df_test[\"Away_Team\"] == team,\r\n",
    "                    1, 0)\r\n",
    "df_test[\"is_HMTL\"] = np.where(df_test[\"Home_Team\"] == team,\r\n",
    "                    1, 0)\r\n",
    "df_test[\"is_MTL\"] = df_test[\"is_AMTL\"] + df_test[\"is_HMTL\"]                    \r\n",
    "df_test = df_test[df_test[\"is_MTL\"] == 1]\r\n",
    "df_test[['Annee','Mois','Jour']] = df_test['Date'].str.split('-',expand=True)\r\n",
    "df_test[\"Annee\"] = pd.to_numeric(df_test[\"Annee\"])\r\n",
    "df_test[\"Mois\"] = pd.to_numeric(df_test[\"Mois\"])\r\n",
    "df_test[\"saison_series\"] =  df_test['Game_Id'].astype(str).str[0]\r\n",
    "df_test = df_test[df_test[\"saison_series\"] == \"2\"]\r\n",
    "df_test[\"Saison\"] = np.where(df_test[\"Mois\"] > 8,\r\n",
    "                    df_test[\"Annee\"], df_test[\"Annee\"] - 1)\r\n",
    "df_test[\"Saison\"] = df_test[\"Saison\"].map(str)\r\n",
    "df_test[\"Game_Id\"] = df_test[\"Saison\"] + df_test[\"Game_Id\"]\r\n",
    "df_agg = df_test.groupby(['Saison']).count()\r\n",
    "df2020 = df_test[df_test[\"Saison\"] == \"2020\"]\r\n",
    "## Tout semble correct!\r\n",
    "df_agg\r\n",
    "#note: df_agg permet de voir le nb de matchs par saison d'une équipe dans la db."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Event</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>is_AMTL</th>\n",
       "      <th>is_HMTL</th>\n",
       "      <th>is_MTL</th>\n",
       "      <th>Annee</th>\n",
       "      <th>Mois</th>\n",
       "      <th>Jour</th>\n",
       "      <th>saison_series</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saison</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Game_Id  Date  Event  Away_Team  Home_Team  is_AMTL  is_HMTL  is_MTL  \\\n",
       "Saison                                                                         \n",
       "2017         81    81     81         81         81       81       81      81   \n",
       "2018         82    82     82         82         82       82       82      82   \n",
       "2019         71    71     71         71         71       71       71      71   \n",
       "2020         55    55     55         55         55       55       55      55   \n",
       "\n",
       "        Annee  Mois  Jour  saison_series  \n",
       "Saison                                    \n",
       "2017       81    81    81             81  \n",
       "2018       82    82    82             82  \n",
       "2019       71    71    71             71  \n",
       "2020       55    55    55             55  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "pbpDates = pd.read_sql(\"SELECT MAX(Date) FROM PBP\", conn)\r\n",
    "maxDate = pbpDates.iloc[0][\"MAX(Date)\"]\r\n",
    "#maxDate = maxDate.strftime(\"%Y-%m-%d\")\r\n",
    "maxDate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2021-02-28'"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#scraper la saison 2016-2017\r\n",
    "#la saison commence le 12 octobre 2016\r\n",
    "# et finit le 9 avril 2017\r\n",
    "\r\n",
    "#rendu au 1er mars 2017 (exécuter le scraping qui est là live)\r\n",
    "scrape_dates(\"2017-03-01\", \"2017-03-31\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping Game  2016020934 2017-03-01\n",
      "Scraping Game  2016020935 2017-03-01\n",
      "Scraping Game  2016020936 2017-03-02\n",
      "Scraping Game  2016020937 2017-03-02\n",
      "Scraping Game  2016020938 2017-03-02\n",
      "Scraping Game  2016020939 2017-03-02\n",
      "Scraping Game  2016020940 2017-03-02\n",
      "Scraping Game  2016020941 2017-03-02\n",
      "Scraping Game  2016020942 2017-03-02\n",
      "Scraping Game  2016020943 2017-03-02\n",
      "Scraping Game  2016020944 2017-03-02\n",
      "Scraping Game  2016020945 2017-03-02\n",
      "Scraping Game  2016020946 2017-03-03\n",
      "Scraping Game  2016020947 2017-03-03\n",
      "Scraping Game  2016020948 2017-03-03\n",
      "Scraping Game  2016020949 2017-03-03\n",
      "Scraping Game  2016020950 2017-03-03\n",
      "Scraping Game  2016020951 2017-03-03\n",
      "Scraping Game  2016020958 2017-03-04\n",
      "Scraping Game  2016020952 2017-03-04\n",
      "Scraping Game  2016020953 2017-03-04\n",
      "Scraping Game  2016020954 2017-03-04\n",
      "Scraping Game  2016020955 2017-03-04\n",
      "Scraping Game  2016020956 2017-03-04\n",
      "Scraping Game  2016020957 2017-03-04\n",
      "Scraping Game  2016020959 2017-03-04\n",
      "Scraping Game  2016020961 2017-03-04\n",
      "Scraping Game  2016020960 2017-03-04\n",
      "Scraping Game  2016020962 2017-03-05\n",
      "Scraping Game  2016020963 2017-03-05\n",
      "Scraping Game  2016020964 2017-03-05\n",
      "Scraping Game  2016020965 2017-03-05\n",
      "Scraping Game  2016020967 2017-03-05\n",
      "Scraping Game  2016020966 2017-03-05\n",
      "Scraping Game  2016020968 2017-03-05\n",
      "Scraping Game  2016020969 2017-03-06\n",
      "Scraping Game  2016020970 2017-03-06\n",
      "Scraping Game  2016020971 2017-03-06\n",
      "Scraping Game  2016020972 2017-03-06\n",
      "Scraping Game  2016020974 2017-03-07\n",
      "Scraping Game  2016020973 2017-03-07\n",
      "Scraping Game  2016020975 2017-03-07\n",
      "Scraping Game  2016020976 2017-03-07\n",
      "Scraping Game  2016020977 2017-03-07\n",
      "Scraping Game  2016020978 2017-03-07\n",
      "Scraping Game  2016020979 2017-03-07\n",
      "Scraping Game  2016020980 2017-03-07\n",
      "Scraping Game  2016020981 2017-03-07\n",
      "Scraping Game  2016020983 2017-03-08\n",
      "Scraping Game  2016020984 2017-03-08\n",
      "Scraping Game  2016020982 2017-03-08\n",
      "Scraping Game  2016020985 2017-03-09\n",
      "Scraping Game  2016020986 2017-03-09\n",
      "Scraping Game  2016020987 2017-03-09\n",
      "Scraping Game  2016020988 2017-03-09\n",
      "Scraping Game  2016020989 2017-03-09\n",
      "Scraping Game  2016020990 2017-03-09\n",
      "Scraping Game  2016020991 2017-03-09\n",
      "Scraping Game  2016020992 2017-03-09\n",
      "Scraping Game  2016020993 2017-03-09\n",
      "Scraping Game  2016020994 2017-03-09\n",
      "Scraping Game  2016020995 2017-03-10\n",
      "Scraping Game  2016020996 2017-03-10\n",
      "Scraping Game  2016020997 2017-03-10\n",
      "Scraping Game  2016020998 2017-03-10\n",
      "Scraping Game  2016020999 2017-03-10\n",
      "Scraping Game  2016021000 2017-03-11\n",
      "Scraping Game  2016021001 2017-03-11\n",
      "Scraping Game  2016021006 2017-03-11\n",
      "Scraping Game  2016021005 2017-03-11\n",
      "Scraping Game  2016021002 2017-03-11\n",
      "Scraping Game  2016021003 2017-03-11\n",
      "Scraping Game  2016021004 2017-03-11\n",
      "Scraping Game  2016021008 2017-03-11\n",
      "Scraping Game  2016021007 2017-03-11\n",
      "Scraping Game  2016021009 2017-03-11\n",
      "Scraping Game  2016021010 2017-03-11\n",
      "Scraping Game  2016021012 2017-03-12\n",
      "Scraping Game  2016021013 2017-03-12\n",
      "Scraping Game  2016021011 2017-03-12\n",
      "Scraping Game  2016021014 2017-03-12\n",
      "Scraping Game  2016021015 2017-03-12\n",
      "Scraping Game  2016021017 2017-03-13\n",
      "Scraping Game  2016021018 2017-03-13\n",
      "Scraping Game  2016021016 2017-03-13\n",
      "Scraping Game  2016021019 2017-03-13\n",
      "Scraping Game  2016021020 2017-03-13\n",
      "Scraping Game  2016021021 2017-03-13\n",
      "Scraping Game  2016021022 2017-03-13\n",
      "Scraping Game  2016021023 2017-03-13\n",
      "Scraping Game  2016021025 2017-03-14\n",
      "Scraping Game  2016021026 2017-03-14\n",
      "Scraping Game  2016021027 2017-03-14\n",
      "Scraping Game  2016021028 2017-03-14\n",
      "Scraping Game  2016021029 2017-03-14\n",
      "Scraping Game  2016021030 2017-03-14\n",
      "Scraping Game  2016021031 2017-03-14\n",
      "Scraping Game  2016021032 2017-03-14\n",
      "Scraping Game  2016021033 2017-03-15\n",
      "Scraping Game  2016021034 2017-03-15\n",
      "Scraping Game  2016021035 2017-03-15\n",
      "Scraping Game  2016021036 2017-03-15\n",
      "Scraping Game  2016021037 2017-03-16\n",
      "Scraping Game  2016021038 2017-03-16\n",
      "Scraping Game  2016021039 2017-03-16\n",
      "Scraping Game  2016021040 2017-03-16\n",
      "Scraping Game  2016021041 2017-03-16\n",
      "Scraping Game  2016021042 2017-03-16\n",
      "Scraping Game  2016021043 2017-03-16\n",
      "Scraping Game  2016021044 2017-03-16\n",
      "Scraping Game  2016021045 2017-03-16\n",
      "Scraping Game  2016021046 2017-03-16\n",
      "Scraping Game  2016021047 2017-03-16\n",
      "Scraping Game  2016021048 2017-03-16\n",
      "Scraping Game  2016021049 2017-03-17\n",
      "Scraping Game  2016021050 2017-03-17\n",
      "Scraping Game  2016021051 2017-03-17\n",
      "Scraping Game  2016021052 2017-03-17\n",
      "Scraping Game  2016021053 2017-03-18\n",
      "Scraping Game  2016021054 2017-03-18\n",
      "Scraping Game  2016021059 2017-03-18\n",
      "Scraping Game  2016021055 2017-03-18\n",
      "Scraping Game  2016021056 2017-03-18\n",
      "Scraping Game  2016021057 2017-03-18\n",
      "Scraping Game  2016021058 2017-03-18\n",
      "Scraping Game  2016021060 2017-03-18\n",
      "Scraping Game  2016021061 2017-03-18\n",
      "Scraping Game  2016021062 2017-03-18\n",
      "Scraping Game  2016021063 2017-03-19\n",
      "Scraping Game  2016021064 2017-03-19\n",
      "Scraping Game  2016021065 2017-03-19\n",
      "Scraping Game  2016021067 2017-03-19\n",
      "Scraping Game  2016021066 2017-03-19\n",
      "Scraping Game  2016021068 2017-03-19\n",
      "Scraping Game  2016021069 2017-03-19\n",
      "Scraping Game  2016021070 2017-03-20\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[0;33mWarning: The number of rows in the Html and json pbp are different because someone fucked up. Will instead merge on Period, Event, Time, and p1_id.\n",
      "\u001b[0m"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraping Game  2016021071 2017-03-20\n",
      "Scraping Game  2016021072 2017-03-20\n",
      "Scraping Game  2016021073 2017-03-20\n",
      "Scraping Game  2016021074 2017-03-20\n",
      "Scraping Game  2016021075 2017-03-21\n",
      "Scraping Game  2016021076 2017-03-21\n",
      "Scraping Game  2016021077 2017-03-21\n",
      "Scraping Game  2016021078 2017-03-21\n",
      "Scraping Game  2016021079 2017-03-21\n",
      "Scraping Game  2016021080 2017-03-21\n",
      "Scraping Game  2016021081 2017-03-21\n",
      "Scraping Game  2016021083 2017-03-21\n",
      "Scraping Game  2016021082 2017-03-21\n",
      "Scraping Game  2016021084 2017-03-21\n",
      "PBP à jour\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Scrape fait'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  }
 ]
}